


Transformer (machine learning model) - Wikipedia





























Transformer (machine learning model)

From Wikipedia, the free encyclopedia



Jump to navigation
Jump to search
Machine learning algorithm used for natural language processing
Part of a series onMachine learninganddata mining
Problems
Classification
Clustering
Regression
Anomaly detection
AutoML
Association rules
Reinforcement learning
Structured prediction
Feature engineering
Feature learning
Online learning
Semi-supervised learning
Unsupervised learning
Learning to rank
Grammar induction


Supervised learning(classification • regression) 
Decision trees
Ensembles
Bagging
Boosting
Random forest
k-NN
Linear regression
Naive Bayes
Artificial neural networks
Logistic regression
Perceptron
Relevance vector machine (RVM)
Support vector machine (SVM)


Clustering
BIRCH
CURE
Hierarchical
k-means
Expectation–maximization (EM)
DBSCAN
OPTICS
Mean-shift


Dimensionality reduction
Factor analysis
CCA
ICA
LDA
NMF
PCA
PGD
t-SNE


Structured prediction
Graphical models
Bayes net
Conditional random field
Hidden Markov


Anomaly detection
k-NN
Local outlier factor


Artificial neural network
Autoencoder
Deep learning
DeepDream
Multilayer perceptron
RNN
LSTM
GRU
ESN
Restricted Boltzmann machine
GAN
SOM
Convolutional neural network
U-Net
Transformer


Reinforcement learning
Q-learning
SARSA
Temporal difference (TD)


Theory
Bias–variance dilemma
Computational learning theory
Empirical risk minimization
Occam learning
PAC learning
Statistical learning
VC theory


Machine-learning venues
NeurIPS
ICML
ML
JMLR
ArXiv:cs.LG


Glossary of artificial intelligence
Glossary of artificial intelligence


Related articles
List of datasets for machine-learning research
Outline of machine learning

vte
The Transformer is a deep learning model introduced in 2017, used primarily in the field of natural language processing (NLP).[1]
Like recurrent neural networks (RNNs), Transformers are designed to handle sequential data, such as natural language, for tasks such as translation and text summarization. However, unlike RNNs, Transformers do not require that the sequential data be processed in order. For example, if the input data is a natural language sentence, the Transformer does not need to process the beginning of it before the end. Due to this feature, the Transformer allows for much more parallelization than RNNs and therefore reduced training times.[1]
Since their introduction, Transformers have become the model of choice for tackling many problems in NLP, replacing older recurrent neural network models such as the long short-term memory (LSTM). Since the Transformer model facilitates more parallelization during training, it has enabled training on larger datasets than was possible before it was introduced. This has led to the development of pretrained systems such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), which have been trained with huge general language datasets, and can be fine-tuned to specific language tasks.[2][3]

Contents

1 Background
2 Architecture

2.1 Scaled dot-product attention

2.1.1 Multi-head attention


2.2 Encoder
2.3 Decoder
2.4 Alternatives


3 Training
4 Implementations
5 Applications
6 References


Background[edit]
Before the introduction of Transformers, most state-of-the-art NLP systems relied on gated recurrent neural networks (RNNs), such as LSTMs and gated recurrent units (GRUs), with added attention mechanisms. The Transformer built on these attention technologies without using an RNN structure, highlighting the fact that the attention mechanisms alone, without recurrent sequential processing, are powerful enough to achieve the performance of RNNs with attention.
Gated RNNs process tokens sequentially, maintaining a state vector that contains a representation of the data seen after every token. To process the 




n

t
h




{\textstyle n^{th}}

 token, the model combines the state representing the sentence up to token 



n
−
1


{\textstyle n-1}

 with the information of the new token to create a new state, representing the sentence up to token 



n


{\textstyle n}

. Theoretically, the information from one token can propagate arbitrarily far down the sequence, if at every point the state continues to encode information about the token. But in practice this mechanism is imperfect: due in part to the vanishing gradient problem, the model's state at the end of a long sentence often does not contain precise, extractable information about early tokens.
This problem was addressed by the introduction of attention mechanisms. Attention mechanisms let a model directly look at, and draw from, the state at any earlier point in the sentence. The attention layer can access all previous states and weighs them according to some learned measure of relevancy to the current token, providing sharper information about far-away relevant tokens. A clear example of the utility of attention is in translation. In an English-to-French translation system, the first word of the French output most probably depends heavily on the beginning of the English input. However, in a classic encoder-decoder LSTM model, in order to produce the first word of the French output the model is only given the state vector of the last English word. Theoretically, this vector can encode information about the whole English sentence, giving the model all necessary knowledge, but in practice this information is often not well preserved. If an attention mechanism is introduced, the model can instead learn to attend to the states of early English tokens when producing the beginning of the French output, giving it a much better concept of what it is translating.
When added to RNNs, attention mechanisms led to large gains in performance. The introduction of the Transformer brought to light the fact that attention mechanisms were powerful in themselves, and that sequential recurrent processing of data was not necessary for achieving the performance gains of RNNs with attention. The Transformer uses an attention mechanism without being an RNN, processing all tokens at the same time and calculating attention weights between them. The fact that Transformers do not rely on sequential processing, and lend themselves very easily to parallelization, allows Transformers to be trained more efficiently on larger datasets.

Architecture[edit]
Like the models invented before it, the Transformer is an encoder-decoder architecture. The encoder consists of a set of encoding layers that processes the input iteratively one layer after another and the decoder consists of a set of decoding layers that does the same thing to the output of the encoder.
The function of each encoder layer is to process its input to generate encodings, containing information about which parts of the inputs are relevant to each other. It passes its set of encodings to the next encoder layer as inputs. Each decoder layer does the opposite, taking all the encodings and processes them, using their incorporated contextual information to generate an output sequence.[4] To achieve this, each encoder and decoder layer makes use of an attention mechanism, which for each input, weighs the relevance of every other input and draws information from them accordingly to produce the output.[5] Each decoder layer also has an additional attention mechanism which draws information from the outputs of previous decoders, before the decoder layer draws information from the encodings. Both the encoder and decoder layers have a feed-forward neural network for additional processing of the outputs, and contain residual connections and layer normalization steps.[5]

Scaled dot-product attention[edit]
The basic building blocks of the Transformer are scaled dot-product attention units. When a sentence is passed into a Transformer model, attention weights are calculated between every token simultaneously. The attention unit produces embeddings for every token in context that contain information not only about the token itself, but also a weighted combination of other relevant tokens weighted by the attention weights.
Concretely, for each attention unit the Transformer model learns three weight matrices; the query weights 




W

Q




{\displaystyle W_{Q}}

, the key weights 




W

K




{\displaystyle W_{K}}

, and the value weights 




W

V




{\displaystyle W_{V}}

. For each token 



i


{\displaystyle i}

, the input word embedding 




x

i




{\displaystyle x_{i}}

 is multiplied with each of the three weight matrices to produce a query vector 




q

i


=

x

i



W

Q




{\displaystyle q_{i}=x_{i}W_{Q}}

, a key vector 




k

i


=

x

i



W

K




{\displaystyle k_{i}=x_{i}W_{K}}

, and a value vector 




v

i


=

x

i



W

V




{\displaystyle v_{i}=x_{i}W_{V}}

. Attention weights are calculated using the query and key vectors: the attention weight 




a

i
j




{\displaystyle a_{ij}}

 from token 



i


{\displaystyle i}

 to token 



j


{\displaystyle j}

 is the dot product between 




q

i




{\displaystyle q_{i}}

 and 




k

j




{\displaystyle k_{j}}

. The attention weights are divided by the square root of the dimension of the key vectors, 






d

k






{\displaystyle {\sqrt {d_{k}}}}

, which stabilizes gradients during training, and passed through a softmax which normalizes the weights to sum to 



1


{\displaystyle 1}

. The fact that 




W

Q




{\displaystyle W_{Q}}

 and 




W

K




{\displaystyle W_{K}}

 are different matrices allows attention to be non-symmetric: if token 



i


{\displaystyle i}

 attends to token 



j


{\displaystyle j}

 (i.e. 




q

i


⋅

k

j




{\displaystyle q_{i}\cdot k_{j}}

 is large), this does not necessarily mean that token 



j


{\displaystyle j}

 will attend to token 



i


{\displaystyle i}

 (i.e. 




q

j


⋅

k

i




{\displaystyle q_{j}\cdot k_{i}}

 is large).  The output of the attention unit for token 



i


{\displaystyle i}

 is the weighted sum of the value vectors of all tokens, weighted by 




a

i
j




{\displaystyle a_{ij}}

, the attention from 



i


{\displaystyle i}

 to each token.
The attention calculation for all tokens can be expressed as one large matrix calculation, which is useful for training due to computational matrix operation optimizations which make matrix operations fast to compute. The matrices 



Q


{\displaystyle Q}

, 



K


{\displaystyle K}

 and 



V


{\displaystyle V}

 are defined as the matrices where the 



i


{\displaystyle i}

th rows are vectors 




q

i




{\displaystyle q_{i}}

, 




k

i




{\displaystyle k_{i}}

, and 




v

i




{\displaystyle v_{i}}

 respectively.









Attention

(
Q
,
K
,
V
)
=

softmax


(



Q

K


T






d

k





)

V






{\displaystyle {\begin{aligned}{\text{Attention}}(Q,K,V)={\text{softmax}}\left({\frac {QK^{\mathrm {T} }}{\sqrt {d_{k}}}}\right)V\end{aligned}}}



Multi-head attention[edit]
One set of 




(


W

Q


,

W

K


,

W

V



)



{\displaystyle \left(W_{Q},W_{K},W_{V}\right)}

 matrices is called an attention head, and each layer in a Transformer model has multiple attention heads. While one attention head attends to the tokens that are relevant to each token, with multiple attention heads the model can learn to do this for different definitions of "relevance". Research has shown that many attention heads in Transformers encode relevance relations that are interpretable by humans. For example there are attention heads that, for every token, attend mostly to the next word, or attention heads that mainly attend from verbs to their direct objects.[6] Since Transformer models have multiple attention heads, they have the possibility of capturing many levels and types of relevance relations, from surface-level to semantic. The multiple outputs for the multi-head attention layer are concatenated to pass into the feed-forward neural network layers.

Encoder[edit]
Each encoder consists of two major components: a self-attention mechanism and a feed-forward neural network. The self-attention mechanism takes in a set of input encodings from the previous encoder and weighs their relevance to each other to generate a set of output encodings. The feed-forward neural network then further processes each output encoding individually. These output encodings are finally passed to the next encoder as its input, as well as the decoders.
The first encoder takes positional information and embeddings of the input sequence as its input, rather than encodings. The positional information is necessary for the Transformer to make use of the order of the sequence, because no other part of the Transformer makes use of this.[1]

Decoder[edit]
Each decoder consists of three major components: a self-attention mechanism, an attention mechanism over the encodings, and a feed-forward neural network. The decoder functions in a similar fashion to the encoder, but an additional attention mechanism is inserted which instead draws relevant information from the encodings generated by the encoders.[1][5]
Like the first encoder, the first decoder takes positional information and embeddings of the output sequence as its input, rather than encodings. Since the transformer should not use the current or future output to predict an output though, the output sequence must be partially masked to prevent this reverse information flow.[1] The last decoder is followed by a final linear transformation and softmax layer, to produce the output probabilities over the vocabulary.

Alternatives[edit]
Training Transformer-based architectures can be very expensive, especially for long sentences.[7] Alternative architectures include the Reformer, which reduces the computational load from 



O
(

L

2


)


{\displaystyle O(L^{2})}

 to 



O
(
L
ln
⁡
L
)


{\displaystyle O(L\ln L)}

, where 



L


{\displaystyle L}

 is the length of the sequence. This is done using locality-sensitive hashing and reversible layers.[8][9]

Training[edit]
Transformers typically undergo semi-supervised learning involving unsupervised pretraining followed by supervised fine-tuning. Pretraining is typically done on a much larger dataset than fine-tuning, due to the restricted availability of labeled training data. Tasks for pretraining and fine-tuning commonly include:

next-sentence prediction[2]
question answering[3]
reading comprehension
sentiment analysis[10]
paraphrasing[10]
Implementations[edit]
The Transformer model has been implemented in major deep learning frameworks such as TensorFlow and PyTorch. Below is pseudo code for an implementation of the Transformer variant known as the "vanilla" transformer:

def vanilla_transformer(enc_inp, dec_inp):
    """Transformer variant known as the "vanilla" transformer."""
    x = embedding(enc_inp) * sqrt(d_m)
    x = x + pos_encoding(x)
    x = dropout(x)
    for _ in range(n_enc_layers):
        attn = multi_head_attention(x, x, x, None)
        attn = dropout(attn)
        attn = layer_normalization(x + attn)

        x = point_wise_ff(attn)
        x = layer_normalization(x + attn)

    # x is at this point the output of the encoder
    enc_out = x

    x = embedding(dec_inp) * sqrt(d_m)
    x = x + pos_encoding(x)
    x = dropout(x)
    mask = causal_mask(x)
    for _ in range(n_dec_layers):
        attn1 = multi_head_attention(x, x, x, mask)
        attn1 = layer_normalization(attn1 + x)

        attn2 = multi_head_attention(attn1, enc_out, enc_out, None)
        attn2 = dropout(attn2)
        attn2 = layer_normalization(attn1 + attn2)

        x = point_wise_ff(attn2)
        x = layer_normalization(attn2 + x)
    return dense(x)

Applications[edit]
The Transformer finds most of its applications in the field of natural language processing (NLP), for example the tasks of machine translation and time series prediction.[11]  Many pretrained models such as GPT-3, GPT-2, BERT, XLNet, and RoBERTa demonstrate the ability of Transformers to perform a wide variety of such NLP-related tasks, and have the potential to find real-world applications.[2][3][12] These may include:

machine translation
document summarization
document generation
named entity recognition (NER)[13]
speech recognition[13]
biological sequence analysis[14]
In 2020, it was shown that the transformer architecture, more specifically GPT-2, could be fine-tuned to play chess.[15]

References[edit]


^ a b c d e Polosukhin, Illia; Kaiser, Lukasz; Gomez, Aidan N.; Jones, Llion; Uszkoreit, Jakob; Parmar, Niki; Shazeer, Noam; Vaswani, Ashish (2017-06-12). "Attention Is All You Need". arXiv:1706.03762 [cs.CL].

^ a b c "Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing". Google AI Blog. Retrieved 2019-08-25.

^ a b c "Better Language Models and Their Implications". OpenAI. 2019-02-14. Retrieved 2019-08-25.

^ "Sequence Modeling with Neural Networks (Part 2): Attention Models". Indico. 2016-04-18. Retrieved 2019-10-15.

^ a b c Alammar, Jay. "The Illustrated Transformer". jalammar.github.io. Retrieved 2019-10-15.

^ Clark, Kevin; Khandelwal, Urvashi; Levy, Omer; Manning, Christopher D. (August 2019). "What Does BERT Look at? An Analysis of BERT's Attention". Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. Florence, Italy: Association for Computational Linguistics: 276–286. doi:10.18653/v1/W19-4828.

^ "Reformer: The Efficient Transformer" (PDF). ICLR 2020.

^ "Task with long sequences".

^ "Reformer: The Efficient Transformer". Google AI Blog. Retrieved 2020-10-22.

^ a b Wang, Alex; Singh, Amanpreet; Michael, Julian; Hill, Felix; Levy, Omer; Bowman, Samuel (2018). "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding". Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. Stroudsburg, PA, USA: Association for Computational Linguistics: 353–355. arXiv:1804.07461. Bibcode:2018arXiv180407461W. doi:10.18653/v1/w18-5446. S2CID 5034059.

^ Allard, Maxime (2019-07-01). "What is a Transformer?". Medium. Retrieved 2019-10-21.

^ Yang, Zhilin Dai, Zihang Yang, Yiming Carbonell, Jaime Salakhutdinov, Ruslan Le, Quoc V. (2019-06-19). XLNet: Generalized Autoregressive Pretraining for Language Understanding. OCLC 1106350082.CS1 maint: multiple names: authors list (link)

^ a b Monsters, Data (2017-09-26). "10 Applications of Artificial Neural Networks in Natural Language Processing". Medium. Retrieved 2019-10-21.

^ Rives, Alexander; Goyal, Siddharth; Meier, Joshua; Guo, Demi; Ott, Myle; Zitnick, C. Lawrence; Ma, Jerry; Fergus, Rob (2019). "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences". bioRxiv 10.1101/622803. doi:10.1101/622803. Cite journal requires |journal= (help)

^ Noever, David; Ciolino, Matt; Kalin, Josh (2020-08-21). "The Chess Transformer: Mastering Play using Generative Language Models". arXiv:2008.04057 [cs.AI].




vteDifferentiable computingGeneral
Differentiable programming
Neural Turing machine
Differentiable neural computer
Automatic differentiation
Neuromorphic engineering
Concepts
Gradient descent
Cable theory
Cluster analysis
Regression analysis
Pattern recognition
Adversarial machine learning
Computational learning theory
Programming languages
Python
Julia
Application
Machine learning
Artificial neural network
Scientific computing
Artificial Intelligence
Hardware
TPU
VPU
Memristor
SpiNNaker
Software library
TensorFlow
PyTorch
ImplementationAudio-visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
Speech recognition
Facial recognition system
Verbal
Word2vec
Transformer
BERT
NMT
Project Debater
Watson
GPT-3
Decisional
AlphaGo
Q-learning
SARSA
OpenAI Five
People
Alex Graves
Ian Goodfellow
Yoshua Bengio
Geoffrey Hinton
Yann LeCun
Andrew Ng
Demis Hassabis
David Silver

 Portals
Computer programming
Technology
 Category
Artificial neural networks
Machine learning





Retrieved from "https://en.wikipedia.org/w/index.php?title=Transformer_(machine_learning_model)&oldid=985192375"
Categories: Artificial neural networksHidden categories: CS1 maint: multiple names: authors listCS1 errors: missing periodicalArticles with short descriptionShort description is different from Wikidata






Navigation menu




Personal tools


Not logged inTalkContributionsCreate accountLog in






Namespaces


ArticleTalk






Variants










Views


ReadEditView history






More







Search



















Navigation


Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate





Contribute


HelpLearn to editCommunity portalRecent changesUpload file





Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageWikidata item





Print/export


Download as PDFPrintable version





Languages


DeutschEuskaraРусскийУкраїнська
Edit links






 This page was last edited on 24 October 2020, at 14:37 (UTC).
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Mobile view
Developers
Statistics
Cookie statement










